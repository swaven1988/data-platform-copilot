# Canonical specification for a data pipeline generated by Data Platform Copilot

job:
  name: example_pipeline
  description: Example Spark pipeline generated by Copilot
  language: pyspark            # pyspark | scala | sql

schedule:
  cron: "0 6 * * *"
  timezone: UTC

source:
  type: table                  # table | path | api
  identifier: raw_db.source_table

target:
  type: table
  identifier: curated_db.target_table
  write_mode: merge             # append | overwrite | merge
  partition_column: data_dt

spark:
  profile: default              # maps to spark_conf files
  dynamic_allocation: true

dq:
  enabled: false                # DQ is OPTIONAL
  mode: none                    # none | sql | scala

metadata:
  owner: data-platform
  environment: dev
  created_by: copilot
  version: 1
